# ğŸ¯ Student Attention Tracker using MediaPipe & OpenCV

A **real-time multi-face attention tracking system** built with **MediaPipe**, **OpenCV**, and **Python**.  
It detects multiple students simultaneously, estimates **gaze direction**, **facial expression**, and **head pose**,  
and logs detailed attention metrics to a CSV file.

---

## ğŸ§  Overview

This project monitors **student attentiveness** in real time â€” ideal for online classes, study monitoring, or human behavior research.  
It uses **face landmarks**, **iris tracking**, and **head pose estimation** to determine whether each student is attentive, distracted, or looking away.  
Facial expressions are also analyzed to infer **emotional engagement** (e.g., smiling = engaged, neutral = bored).

---

## âš™ï¸ Features

âœ… Tracks **up to 50 faces** simultaneously  
âœ… Estimates **gaze direction** (left, right, away, center)  
âœ… Estimates **head pose** with 3D direction line  
âœ… Detects **facial expressions** (smile, sad, angry, neutral)  
âœ… Calculates **class attention percentage**  
âœ… Generates **CSV log reports** with all metrics  
âœ… Displays **distraction warning alerts** in real time  

---

<details>
<summary>ğŸ“¦ <b>Installation Instructions</b> (click to expand)</summary>

### ğŸ§° Requirements

- Python 3.8 or newer  
- A working webcam  
- Libraries:  
  ```bash
  pip install opencv-python mediapipe numpy
<details> <summary>ğŸ—‚ï¸ <b>Project Structure</b></summary>
ğŸ“ student-attention-tracker/
â”‚
â”œâ”€â”€ attention_tracker.py        # Main source code
â”œâ”€â”€ attention_log.csv            # Auto-generated logs
â””â”€â”€ README.md                    # Project documentation

</details>
â–¶ï¸ Running the Project

Run the Python script:

python attention_tracker.py

ğŸ’» What Happens:

Webcam opens and starts detecting faces.

Each studentâ€™s gaze, expression, and head pose are analyzed.

Real-time bounding boxes and status text are displayed.

Data is logged into attention_log.csv.

Press ESC to exit the program.

ğŸ“Š CSV Log Format
Timestamp	Student_ID	Gaze_Status	Attention	Expression	Engagement	Final_Status
2025-10-15 10:42:30	1	Attentive	attentive	Smiling	engaged	Focused
2025-10-15 10:42:31	2	Looking Left	distracted	Neutral	bored	Distracted

ğŸ—’ï¸ The file attention_log.csv is automatically created in the project directory.

ğŸ¨ Color & Status Legend
Status	Color	Meaning
ğŸŸ¢ Attentive	Green	Focused on screen
ğŸŸ  Looking Away	Orange	Temporarily distracted
ğŸ”´ Distracted	Red	Lost attention for >3 seconds
ğŸŸ¡ Engaged	Yellow	Smiling / participating
ğŸ”µ Confused	Blue	Unsure / thinking
ğŸŸ£ Bored	Purple	Neutral / passive
<details> <summary>ğŸ§® <b>How It Works (Technical Details)</b></summary>
1ï¸âƒ£ Face & Iris Tracking

Uses MediaPipe FaceMesh (468 landmarks) to locate eyes, iris centers, mouth, eyebrows, etc.

2ï¸âƒ£ Gaze Estimation

Compares iris center position with eye corner landmarks to determine direction:

Left / Right / Away / Attentive

3ï¸âƒ£ Expression Analysis

Analyzes ratios of mouth openness, eyebrow height, and mouth slope:

Smile â†’ engaged

Sad â†’ confused

Angry â†’ distracted

Neutral â†’ bored

4ï¸âƒ£ Head Pose Estimation

cv2.solvePnP() computes 3D rotation and draws a line projecting from the nose tip to show head orientation.

5ï¸âƒ£ Attention Logic

If gaze â‰  center or head pose deviates â†’ mark as distracted

If time_since_last_attention > 3s â†’ trigger warning alert

Aggregates per-frame data to compute Class Attention %

</details>
âš ï¸ Notes & Recommendations

Ensure good lighting and frontal face visibility.

Adjust thresholds (e.g. SMILE_THRESH, attention_threshold) for your use case.

Works best in 720p mode for faster inference.

For multi-camera setups, modify cv2.VideoCapture(index).

<details> <summary>ğŸš€ <b>Future Enhancements</b></summary>

 Add emotion recognition using DeepFace or FER

 Implement blink/drowsiness detection

 Integrate Gaze360 or ETH-XGaze datasets for improved gaze accuracy

 Build Streamlit/Flask dashboard for analytics visualization

 Store logs in a database (SQLite, Firebase)

 Add audio-based attention cues or voice detection

</details>
ğŸ‘¨â€ğŸ’» Author

ENAN
ğŸ”¬ Real-Time Computer Vision & Deep Learning Enthusiast
ğŸ“§ [Optional: Add your GitHub or email link here]

ğŸ“œ License

This project is open-source under the MIT License.
You may freely use, modify, and distribute with attribution.

â­ If you find this useful, please star the repository and share it!
Let's make classrooms smarter through AI ğŸ‘ï¸â€ğŸ§ 
